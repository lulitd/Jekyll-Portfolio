---
layout: portfolioItem
title: Encounter
link_to: portfolio/encounter
useDarkNav: false
AnimLogo: true
rank: 1 # determines order lowest to highest!
#Images
image: images/work/thumb/encounter.jpg
headerImage: images/work/header/encounter.jpg
headerImage-md: images/work/header/encounter.jpg
headerImage-lg: images/work/header/encounter.jpg
#content
date: 2016-04-13
collaboration:
  -  'Youhan Guan'
  -  'Rose Mengmei Zhou'
youtubeURL: "https://www.youtube.com/embed/zEDyT4MUois"
vimeoURL: #
Tools:
  - 'Unity3D (c#)'
  - 'Cinema4D'
  - 'Microsoft Kinect'
  - 'Smartphones'
  - 'Projector'
exhibition:
  - York University Undergraduate Research Fair (February 2016)
  - Digital Media Showcase (April 2016)
  - Computational Beauty exhibition(April 2016)
  - Digifest Festival (April 2016)
press: #
categories:
  - 'UX'
  - 'Motion Tracking'
  - 'Content Creation'
  - 'Programming'
selectedCat: 'Motion Tracking' # determines what is shown in related works
---
Encounter is an installation where participants can interact with artificial creatures and environments using mixed reality modes of interaction. It was created for the Digital Media Project course as part of the Digital Media Program.

It consists of two zone for interaction: The Tangible Objects Station and the Projection Zone. In the Tangible Objects Station participants have a map of the environment, where they become "city planners". Participants can physically move objects on the map and shape the virtual world. Using a smartphone/tablet device and a custom app participants can find out more information about the environment using augmented reality. The app recognizes various objects and images and communicates any changes the "city planners" make.

In the projection zone, participants are invited to walk and explore the virtual world, as if they are walking through a park. A view of virtual world is projected onto a wall (or displayed on a monitor). Participants gain an avatar simply by walking into the space. Through the use of the Microsoft Kinect, participants are able to control these avatars via body gestures. The environment and creatures of this ecosystem are responsive to their gestures. Any changes made by the city planners are reflected in the projected view in real time.

For this Project, my primary focus were the participant's interactions in the projection space, projection design and world modelling.
